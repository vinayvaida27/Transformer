{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "## Multi Layer Neural network"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## in previous Notebook we have seen used single layer perceptron neural network and  Bi gram stats model both of them cannot capture the context better, they dont sound the names better\n",
    "# so in this notebook we use the multilayer perceptron which are useful to generate the meaning full name\n",
    "\n",
    "# so the problem with bi-gram model we face is we are able to capture the context of 2 characters at a time.(that gives us 27 character * 27 characters = 729 possibilities combination comes in context)\n",
    "# if we have the 3 characters as context  we would get (27*27*27 =19,623 combinations context) generating count vector normalizing and everything becomes difficult now.\n",
    "# the modeling approach we gonna follow  is from this research paper bengio et al. 2003 (https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "\n",
    "\n"
   ],
   "id": "871b15627454a0ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T14:27:29.158970Z",
     "start_time": "2025-07-11T14:27:26.698152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "id": "a2f91463e9020a1c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T14:38:09.748243Z",
     "start_time": "2025-07-11T14:38:09.715029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:5]"
   ],
   "id": "cdab35aafdd2ac69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T14:40:18.233858Z",
     "start_time": "2025-07-11T14:40:18.228269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {\n",
    "    s: i+1 for i,s in enumerate(chars)\n",
    "}\n",
    "stoi['.'] = 0\n",
    "itos = { i:s for s,i in stoi.items() }\n"
   ],
   "id": "20a56c1d5b400d4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating dataset for Neural Networks from Text File to Input Tensor and Output Tensor",
   "id": "67379305a8347179"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T15:19:36.866331Z",
     "start_time": "2025-07-11T15:19:36.860488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## data set for neural network\n",
    "\n",
    "block_size = 3 #Context_length: how many characters do we take to predict the next one?\n",
    "X,Y =[],[] # x are inputs and Y are labels\n",
    "\n",
    "for w in words[:1]:\n",
    "\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "\n",
    "        print(\"input data : \",''.join(itos[i] for i in context), \", Output :\", '=', itos[ix])\n",
    "        print('context :', context)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(\"input tensor :\", X)\n",
    "\n",
    "print(\"output tensor :\", Y)"
   ],
   "id": "df30e971691caba6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "input data :  ... , Output : = e\n",
      "context : [0, 0, 0]\n",
      "input data :  ..e , Output : = m\n",
      "context : [0, 0, 5]\n",
      "input data :  .em , Output : = m\n",
      "context : [0, 5, 13]\n",
      "input data :  emm , Output : = a\n",
      "context : [5, 13, 13]\n",
      "input data :  mma , Output : = .\n",
      "context : [13, 13, 1]\n",
      "\n",
      "\n",
      "input tensor : tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1]])\n",
      "output tensor : tensor([ 5, 13, 13,  1,  0])\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Above output explanation\n",
    "\n",
    "you can notes how the input data is store in the input tensor it is simple\n",
    "\n",
    "input data :  ... , Output : = e\n",
    "context : [0, 0, 0]\n",
    "\n",
    "when we get input '...' we have the o/p as 'e'\n",
    "similary i/p = '..e' => o/p = 'm'\n",
    "\n",
    "-> we are trying to take context of 3 character at same time and trying to predict the o/p of what character come next and run in the loop\n",
    "\n",
    "1)so we are able to use above block and change the parameters like block size to get different context\n",
    "2) if we consider all the input and one cblock size we are able to get the whole i/p and o/p data\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ],
   "id": "9aafb3d72ea457d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Block size = 5",
   "id": "86a2e1a58372fa34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T15:24:12.169734Z",
     "start_time": "2025-07-11T15:24:12.164399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "block_size = 5 #Context_length: how many characters do we take to predict the next one?\n",
    "X,Y =[],[] # x are inputs and Y are labels\n",
    "\n",
    "for w in words[:1]:\n",
    "\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "\n",
    "        print(\"input data : \",''.join(itos[i] for i in context), \", Output :\", '=', itos[ix])\n",
    "        print('context :', context)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(\"input tensor :\", X)\n",
    "\n",
    "print(\"output tensor :\", Y)"
   ],
   "id": "bbf8520f0eb7ca04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "input data :  ..... , Output : = e\n",
      "context : [0, 0, 0, 0, 0]\n",
      "input data :  ....e , Output : = m\n",
      "context : [0, 0, 0, 0, 5]\n",
      "input data :  ...em , Output : = m\n",
      "context : [0, 0, 0, 5, 13]\n",
      "input data :  ..emm , Output : = a\n",
      "context : [0, 0, 5, 13, 13]\n",
      "input data :  .emma , Output : = .\n",
      "context : [0, 5, 13, 13, 1]\n",
      "\n",
      "\n",
      "input tensor : tensor([[ 0,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  5],\n",
      "        [ 0,  0,  0,  5, 13],\n",
      "        [ 0,  0,  5, 13, 13],\n",
      "        [ 0,  5, 13, 13,  1]])\n",
      "output tensor : tensor([ 5, 13, 13,  1,  0])\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### above we are trying to take 5 character as input and predicting what comes next as o/p",
   "id": "9695ecaf3199aba3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:14.355639Z",
     "start_time": "2025-07-11T18:32:14.349067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "block_size = 3 #Context_length: how many characters do we take to predict the next one?\n",
    "X,Y =[],[] # x are inputs and Y are labels\n",
    "\n",
    "for w in words[:5]:\n",
    "\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "\n",
    "        #print(\"input data : \",''.join(itos[i] for i in context), \", Output :\", '=', itos[ix])\n",
    "        #print('context :', context)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "X"
   ],
   "id": "ab013fef48297968",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:15.369951Z",
     "start_time": "2025-07-11T18:32:15.363018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(Y)"
   ],
   "id": "9fbc192d9e0b8e45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     0\n",
       "0    5\n",
       "1   13\n",
       "2   13\n",
       "3    1\n",
       "4    0\n",
       "5   15\n",
       "6   12\n",
       "7    9\n",
       "8   22\n",
       "9    9\n",
       "10   1\n",
       "11   0\n",
       "12   1\n",
       "13  22\n",
       "14   1\n",
       "15   0\n",
       "16   9\n",
       "17  19\n",
       "18   1\n",
       "19   2\n",
       "20   5\n",
       "21  12\n",
       "22  12\n",
       "23   1\n",
       "24   0\n",
       "25  19\n",
       "26  15\n",
       "27  16\n",
       "28   8\n",
       "29   9\n",
       "30   1\n",
       "31   0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:16.017673Z",
     "start_time": "2025-07-11T18:32:16.014003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "1. now the Test data with the block_size/context = 3 is ready and o/p is also ready fo the model to get trained on.\n",
    "2.\n",
    "\"\"\""
   ],
   "id": "db5fdadbdf89bd9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. now the Test data with the block_size/context = 3 is ready and o/p is also ready fo the model to get trained on.\\n2.\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:16.769833Z",
     "start_time": "2025-07-11T18:32:16.766306Z"
    }
   },
   "cell_type": "code",
   "source": "(X.shape, X.dtype), (Y.shape, Y.dtype)",
   "id": "f6abc7661359b0cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((torch.Size([32, 3]), torch.int64), (torch.Size([32]), torch.int64))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:17.278113Z",
     "start_time": "2025-07-11T18:32:17.274717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## so our tensor matrix x has 228146 rows and 3 columns only both of there dtype is integer\n",
    "\n",
    "## In paper they have 17,000 words and they embedded in 30 dimensional\n",
    "\n",
    "## in our case we have only 27 possible characters so let's consider 2- dimensional space so we have 27 charcter with 2 dimenisonal space(27*2) tensor"
   ],
   "id": "a8badac9970dacd9",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:17.804789Z",
     "start_time": "2025-07-11T18:32:17.798789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# let embedded the 2 random numbers with 27*2\n",
    "\n",
    "C = torch.randn((27,2)) # the weight Matrix is C it is represented as C because of research paper\n",
    "C"
   ],
   "id": "90c4cf80a2bf2f3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4055,  0.7574],\n",
       "        [ 0.4587, -0.2725],\n",
       "        [ 1.7137, -1.5466],\n",
       "        [-1.7004, -0.1629],\n",
       "        [-1.2717, -0.3085],\n",
       "        [-0.1866,  1.1372],\n",
       "        [ 0.1859, -0.9961],\n",
       "        [-0.5628,  1.3539],\n",
       "        [-0.5182,  0.8825],\n",
       "        [-0.2112,  1.3888],\n",
       "        [ 1.1893, -0.7963],\n",
       "        [-0.4880, -1.0680],\n",
       "        [ 0.1820,  0.4371],\n",
       "        [-0.9799, -1.1722],\n",
       "        [ 0.7273,  2.2199],\n",
       "        [ 1.1401,  0.2118],\n",
       "        [ 1.0594,  1.6841],\n",
       "        [-1.7480, -0.4442],\n",
       "        [-0.2313, -0.3345],\n",
       "        [ 0.4041,  0.3533],\n",
       "        [ 0.0263,  0.6341],\n",
       "        [-0.4183, -0.9250],\n",
       "        [-0.6277, -2.1561],\n",
       "        [ 2.2610,  1.2614],\n",
       "        [ 1.8530, -0.5818],\n",
       "        [ 0.9229, -1.4164],\n",
       "        [ 0.5225, -0.5810]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:19.365642Z",
     "start_time": "2025-07-11T18:32:19.361350Z"
    }
   },
   "cell_type": "code",
   "source": "C[5]",
   "id": "8d1c6c7ebbdd3d61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1866,  1.1372])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:20.953872Z",
     "start_time": "2025-07-11T18:32:20.948649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Example\n",
    "\n",
    "(F.one_hot(torch.tensor(5), num_classes=27).float()) @ C"
   ],
   "id": "f3a337bff25f2141",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1866,  1.1372])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:21.755564Z",
     "start_time": "2025-07-11T18:32:21.752566Z"
    }
   },
   "cell_type": "code",
   "source": "# if we multiply the weight vector(C) * index_vector/one_hot encoding vector of the input(X) = we get the Result from the first layer",
   "id": "91bf9541d1ecd513",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:22.764108Z",
     "start_time": "2025-07-11T18:32:22.759365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "C = torch.randn((27,2))\n",
    "C ## c is noting buit one type of encoding"
   ],
   "id": "9f163d4210a00987",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3028,  1.6685],\n",
       "        [-1.8216,  1.5519],\n",
       "        [-0.6952, -0.2872],\n",
       "        [-0.5589,  1.1143],\n",
       "        [-1.3582, -0.5364],\n",
       "        [-0.2447,  0.2761],\n",
       "        [-0.7507,  1.7232],\n",
       "        [ 0.3503, -1.4699],\n",
       "        [-0.9065, -1.6470],\n",
       "        [-0.3676,  1.0258],\n",
       "        [-0.8222,  0.9258],\n",
       "        [ 0.1590, -0.9919],\n",
       "        [ 0.6491, -2.0204],\n",
       "        [ 0.7483,  0.2963],\n",
       "        [-0.4171, -0.4603],\n",
       "        [-1.2425, -1.0488],\n",
       "        [ 0.4187,  1.0417],\n",
       "        [ 0.0578,  1.9587],\n",
       "        [ 0.4469, -0.5635],\n",
       "        [-1.1468, -0.5540],\n",
       "        [ 0.2199, -1.3478],\n",
       "        [-1.1349, -1.0798],\n",
       "        [ 0.4670,  0.2617],\n",
       "        [ 0.6398, -1.5389],\n",
       "        [-0.1622,  1.3953],\n",
       "        [-0.0336, -1.7348],\n",
       "        [ 0.8888, -0.5408]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:23.526755Z",
     "start_time": "2025-07-11T18:32:23.521641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# we want to encode one number 5 we can simply pass this number to the Embedding tensor C and get the output i.e.,\n",
    "\n",
    "C[5] #Give embedding of 5 in 2d Vector Space"
   ],
   "id": "655e7724225f6ce6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2447,  0.2761])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:24.371911Z",
     "start_time": "2025-07-11T18:32:24.366381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# what if the embedding is like list\n",
    "\n",
    "print(C[[2,3,4]]) # we got the embedding of 3 integer vector as below\n"
   ],
   "id": "7af03145d23088db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6952, -0.2872],\n",
      "        [-0.5589,  1.1143],\n",
      "        [-1.3582, -0.5364]])\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:25.206035Z",
     "start_time": "2025-07-11T18:32:25.201358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# what if we give the tensor input to get embedding\n",
    "\n",
    "print(C[torch.tensor([5,6,7,7,7,7,7,7,])]) # still we are able to get the embedding by giving tensor matrix as input"
   ],
   "id": "684794359b52802b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2447,  0.2761],\n",
      "        [-0.7507,  1.7232],\n",
      "        [ 0.3503, -1.4699],\n",
      "        [ 0.3503, -1.4699],\n",
      "        [ 0.3503, -1.4699],\n",
      "        [ 0.3503, -1.4699],\n",
      "        [ 0.3503, -1.4699],\n",
      "        [ 0.3503, -1.4699]])\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:26.302891Z",
     "start_time": "2025-07-11T18:32:26.298789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Full explanation of C\n",
    "\n",
    " C is the embedding vector  when you pass the single integer -> we get the embedding of that single integer\n",
    "if we pass list to embedding vector c -> we goonna get embedding for that list passed\n",
    "if we pass the tensor to embedding vector -. we gonna get th emebedding for that tensor\n",
    "\n",
    "\n",
    "to get emebedding for anything we need to pass it to the C\n",
    "\n",
    "\"\"\""
   ],
   "id": "1e5bc35f693b87b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFull explanation of C\\n\\n C is the embedding vector  when you pass the single integer -> we get the embedding of that single integer\\nif we pass list to embedding vector c -> we goonna get embedding for that list passed\\nif we pass the tensor to embedding vector -. we gonna get th emebedding for that tensor\\n\\n\\nto get emebedding for anything we need to pass it to the C\\n\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:27.376023Z",
     "start_time": "2025-07-11T18:32:27.369132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding = C[X]\n",
    "embedding"
   ],
   "id": "84e3f5464cbff43f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-0.2447,  0.2761]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-0.2447,  0.2761],\n",
       "         [ 0.7483,  0.2963]],\n",
       "\n",
       "        [[-0.2447,  0.2761],\n",
       "         [ 0.7483,  0.2963],\n",
       "         [ 0.7483,  0.2963]],\n",
       "\n",
       "        [[ 0.7483,  0.2963],\n",
       "         [ 0.7483,  0.2963],\n",
       "         [-1.8216,  1.5519]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-1.2425, -1.0488]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.2425, -1.0488],\n",
       "         [ 0.6491, -2.0204]],\n",
       "\n",
       "        [[-1.2425, -1.0488],\n",
       "         [ 0.6491, -2.0204],\n",
       "         [-0.3676,  1.0258]],\n",
       "\n",
       "        [[ 0.6491, -2.0204],\n",
       "         [-0.3676,  1.0258],\n",
       "         [ 0.4670,  0.2617]],\n",
       "\n",
       "        [[-0.3676,  1.0258],\n",
       "         [ 0.4670,  0.2617],\n",
       "         [-0.3676,  1.0258]],\n",
       "\n",
       "        [[ 0.4670,  0.2617],\n",
       "         [-0.3676,  1.0258],\n",
       "         [-1.8216,  1.5519]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-1.8216,  1.5519]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.8216,  1.5519],\n",
       "         [ 0.4670,  0.2617]],\n",
       "\n",
       "        [[-1.8216,  1.5519],\n",
       "         [ 0.4670,  0.2617],\n",
       "         [-1.8216,  1.5519]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-0.3676,  1.0258]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-0.3676,  1.0258],\n",
       "         [-1.1468, -0.5540]],\n",
       "\n",
       "        [[-0.3676,  1.0258],\n",
       "         [-1.1468, -0.5540],\n",
       "         [-1.8216,  1.5519]],\n",
       "\n",
       "        [[-1.1468, -0.5540],\n",
       "         [-1.8216,  1.5519],\n",
       "         [-0.6952, -0.2872]],\n",
       "\n",
       "        [[-1.8216,  1.5519],\n",
       "         [-0.6952, -0.2872],\n",
       "         [-0.2447,  0.2761]],\n",
       "\n",
       "        [[-0.6952, -0.2872],\n",
       "         [-0.2447,  0.2761],\n",
       "         [ 0.6491, -2.0204]],\n",
       "\n",
       "        [[-0.2447,  0.2761],\n",
       "         [ 0.6491, -2.0204],\n",
       "         [ 0.6491, -2.0204]],\n",
       "\n",
       "        [[ 0.6491, -2.0204],\n",
       "         [ 0.6491, -2.0204],\n",
       "         [-1.8216,  1.5519]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.3028,  1.6685],\n",
       "         [-1.1468, -0.5540]],\n",
       "\n",
       "        [[-1.3028,  1.6685],\n",
       "         [-1.1468, -0.5540],\n",
       "         [-1.2425, -1.0488]],\n",
       "\n",
       "        [[-1.1468, -0.5540],\n",
       "         [-1.2425, -1.0488],\n",
       "         [ 0.4187,  1.0417]],\n",
       "\n",
       "        [[-1.2425, -1.0488],\n",
       "         [ 0.4187,  1.0417],\n",
       "         [-0.9065, -1.6470]],\n",
       "\n",
       "        [[ 0.4187,  1.0417],\n",
       "         [-0.9065, -1.6470],\n",
       "         [-0.3676,  1.0258]],\n",
       "\n",
       "        [[-0.9065, -1.6470],\n",
       "         [-0.3676,  1.0258],\n",
       "         [-1.8216,  1.5519]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:28.179633Z",
     "start_time": "2025-07-11T18:32:28.175253Z"
    }
   },
   "cell_type": "code",
   "source": "embedding.shape",
   "id": "fdfda423e7a1a6e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "now our input is embeeded",
   "id": "b540d145d62b6000"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:29.627234Z",
     "start_time": "2025-07-11T18:32:29.614198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# so to convert the input vector to 2 dimensional space there are manu ways to represent it\n",
    "# but one of the effective and easiest way pass dotview  .view(x,6)\n",
    "\n",
    "embedding.view(-1, 6)"
   ],
   "id": "458f836736cf59cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3028,  1.6685, -1.3028,  1.6685, -1.3028,  1.6685],\n",
       "        [-1.3028,  1.6685, -1.3028,  1.6685, -0.2447,  0.2761],\n",
       "        [-1.3028,  1.6685, -0.2447,  0.2761,  0.7483,  0.2963],\n",
       "        [-0.2447,  0.2761,  0.7483,  0.2963,  0.7483,  0.2963],\n",
       "        [ 0.7483,  0.2963,  0.7483,  0.2963, -1.8216,  1.5519],\n",
       "        [-1.3028,  1.6685, -1.3028,  1.6685, -1.3028,  1.6685],\n",
       "        [-1.3028,  1.6685, -1.3028,  1.6685, -1.2425, -1.0488],\n",
       "        [-1.3028,  1.6685, -1.2425, -1.0488,  0.6491, -2.0204],\n",
       "        [-1.2425, -1.0488,  0.6491, -2.0204, -0.3676,  1.0258],\n",
       "        [ 0.6491, -2.0204, -0.3676,  1.0258,  0.4670,  0.2617],\n",
       "        [-0.3676,  1.0258,  0.4670,  0.2617, -0.3676,  1.0258],\n",
       "        [ 0.4670,  0.2617, -0.3676,  1.0258, -1.8216,  1.5519],\n",
       "        [-1.3028,  1.6685, -1.3028,  1.6685, -1.3028,  1.6685],\n",
       "        [-1.3028,  1.6685, -1.3028,  1.6685, -1.8216,  1.5519],\n",
       "        [-1.3028,  1.6685, -1.8216,  1.5519,  0.4670,  0.2617],\n",
       "        [-1.8216,  1.5519,  0.4670,  0.2617, -1.8216,  1.5519],\n",
       "        [-1.3028,  1.6685, -1.3028,  1.6685, -1.3028,  1.6685],\n",
       "        [-1.3028,  1.6685, -1.3028,  1.6685, -0.3676,  1.0258],\n",
       "        [-1.3028,  1.6685, -0.3676,  1.0258, -1.1468, -0.5540],\n",
       "        [-0.3676,  1.0258, -1.1468, -0.5540, -1.8216,  1.5519],\n",
       "        [-1.1468, -0.5540, -1.8216,  1.5519, -0.6952, -0.2872],\n",
       "        [-1.8216,  1.5519, -0.6952, -0.2872, -0.2447,  0.2761],\n",
       "        [-0.6952, -0.2872, -0.2447,  0.2761,  0.6491, -2.0204],\n",
       "        [-0.2447,  0.2761,  0.6491, -2.0204,  0.6491, -2.0204],\n",
       "        [ 0.6491, -2.0204,  0.6491, -2.0204, -1.8216,  1.5519],\n",
       "        [-1.3028,  1.6685, -1.3028,  1.6685, -1.3028,  1.6685],\n",
       "        [-1.3028,  1.6685, -1.3028,  1.6685, -1.1468, -0.5540],\n",
       "        [-1.3028,  1.6685, -1.1468, -0.5540, -1.2425, -1.0488],\n",
       "        [-1.1468, -0.5540, -1.2425, -1.0488,  0.4187,  1.0417],\n",
       "        [-1.2425, -1.0488,  0.4187,  1.0417, -0.9065, -1.6470],\n",
       "        [ 0.4187,  1.0417, -0.9065, -1.6470, -0.3676,  1.0258],\n",
       "        [-0.9065, -1.6470, -0.3676,  1.0258, -1.8216,  1.5519]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:35.728137Z",
     "start_time": "2025-07-11T18:32:35.724020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## now if we want to pass it to the second layer\n",
    "\n",
    "# consider second layer as weight w1 and bias b1\n",
    "# then o/p of second layer = i/p @w1 + b1\n",
    "\n",
    "#lets consider we have 100 weights in second layer such that we have 100 biases in second layer too h = tanh(w1*x1 + b1)\n",
    "\n",
    "W1 = torch.rand((6,100))\n",
    "B1 = torch.rand(100)"
   ],
   "id": "1199d474f81bf1fd",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:32:36.568901Z",
     "start_time": "2025-07-11T18:32:36.562970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "h = torch.tanh(embedding.view(-1, 6) @ W1 + B1)\n",
    "h"
   ],
   "id": "826ec8ef8103ae02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8388, -0.1336,  0.7544,  ...,  0.9729,  0.7419,  0.8800],\n",
       "        [ 0.9551,  0.0895,  0.6731,  ...,  0.9686,  0.5060,  0.8940],\n",
       "        [ 0.9318,  0.5509,  0.7485,  ...,  0.8910,  0.7745,  0.9290],\n",
       "        ...,\n",
       "        [ 0.2615, -0.9723, -0.2959,  ..., -0.5677, -0.9524, -0.4116],\n",
       "        [-0.6253,  0.4373, -0.7034,  ..., -0.1920,  0.8582,  0.8393],\n",
       "        [-0.4209, -0.9024, -0.7608,  ..., -0.5827, -0.9162, -0.5791]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:34:27.693829Z",
     "start_time": "2025-07-11T18:34:27.687829Z"
    }
   },
   "cell_type": "code",
   "source": "h.shape",
   "id": "b341240b34bf1f18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:39:14.252668Z",
     "start_time": "2025-07-11T18:39:14.247632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "-> We are creating the output layer here -> output layer = weight * hidden layer + Bias\n",
    "\n",
    "-> but we have only 27 character, so the layer needs to be 27 weights + 27 weights i.e., we need to take 100 inputs and give only 27 o/p\n",
    "\n",
    "->\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "W2 = torch.randn((100,27))\n",
    "B2 = torch.randn(27)"
   ],
   "id": "bffc94ac57b68e38",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:39:52.535535Z",
     "start_time": "2025-07-11T18:39:52.524574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits = h @ W2+ B2\n",
    "logits"
   ],
   "id": "381af8ca36b3c856",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0882e+01,  1.0689e+01,  8.3067e+00, -1.0882e-01,  8.5998e+00,\n",
       "          3.6865e+00,  1.2778e+01,  8.3188e+00,  6.1602e+00, -2.9399e+00,\n",
       "          2.6398e+00,  2.2891e+00, -1.8251e+00, -2.0688e+00, -8.5253e+00,\n",
       "         -5.1564e+00, -4.8787e+00,  8.0808e+00, -3.9176e+00,  6.1599e+00,\n",
       "         -1.2264e+01, -3.5532e+00,  3.3294e+00, -1.9572e+00, -3.0141e+00,\n",
       "         -6.7364e-01, -4.7768e+00],\n",
       "        [ 8.9172e+00,  9.2561e+00,  9.5637e+00, -1.7320e+00,  5.9928e+00,\n",
       "          7.5574e-01,  1.0065e+01,  5.0416e+00,  7.2937e+00, -2.6560e+00,\n",
       "          2.9372e+00,  1.6444e+00, -4.1836e+00, -3.3501e+00, -7.1241e+00,\n",
       "         -4.5624e+00, -5.4429e+00,  9.6493e+00, -3.5000e+00,  1.3368e+01,\n",
       "         -1.2022e+01, -3.4132e+00, -2.6708e+00, -1.9486e+00, -2.9384e+00,\n",
       "         -4.4481e+00, -3.8054e+00],\n",
       "        [ 9.5722e+00,  8.4163e+00,  1.2724e+01, -7.7386e+00,  7.9873e+00,\n",
       "         -1.7400e+00,  8.5007e+00,  6.1290e+00,  3.5561e+00,  6.5908e-01,\n",
       "          3.4000e+00,  1.2511e+00, -5.8269e+00, -6.2223e+00, -8.8090e+00,\n",
       "         -7.8452e+00, -3.8330e+00,  6.6334e+00, -6.2615e+00,  2.2491e+01,\n",
       "         -2.3499e+01, -6.1819e+00, -3.1185e-01,  4.9001e+00, -2.5282e+00,\n",
       "         -5.6628e+00, -1.2037e+01],\n",
       "        [ 8.3969e+00,  3.7401e+00,  1.0835e+01, -6.6458e+00,  7.1897e+00,\n",
       "         -2.4401e+00,  1.3458e+01,  2.6903e+00,  2.3094e+00,  1.4334e+00,\n",
       "          4.8546e+00, -1.6836e+00, -4.0277e+00, -7.8780e+00, -1.3559e+01,\n",
       "         -6.5652e+00, -9.2525e+00,  5.2276e+00, -9.2709e+00,  2.5837e+01,\n",
       "         -2.9424e+01, -4.3080e+00,  2.2624e+00,  1.1360e+01,  1.0914e+00,\n",
       "          1.7015e+00, -1.6295e+01],\n",
       "        [ 1.0147e+01,  7.4232e+00,  7.4550e+00, -1.1171e+00,  6.9059e+00,\n",
       "          2.6176e+00,  1.4667e+01,  3.5718e+00,  1.6078e+00,  2.4885e+00,\n",
       "          3.3533e+00,  1.6876e+00,  2.8731e-01, -7.3418e+00, -1.0365e+01,\n",
       "         -6.4053e+00, -5.6171e+00,  3.5459e+00, -5.9972e+00,  1.1102e+01,\n",
       "         -1.9450e+01,  2.3285e-02,  2.6974e+00,  1.0926e+01, -1.0453e+00,\n",
       "          3.8366e+00, -1.3921e+01],\n",
       "        [ 1.0882e+01,  1.0689e+01,  8.3067e+00, -1.0882e-01,  8.5998e+00,\n",
       "          3.6865e+00,  1.2778e+01,  8.3188e+00,  6.1602e+00, -2.9399e+00,\n",
       "          2.6398e+00,  2.2891e+00, -1.8251e+00, -2.0688e+00, -8.5253e+00,\n",
       "         -5.1564e+00, -4.8787e+00,  8.0808e+00, -3.9176e+00,  6.1599e+00,\n",
       "         -1.2264e+01, -3.5532e+00,  3.3294e+00, -1.9572e+00, -3.0141e+00,\n",
       "         -6.7364e-01, -4.7768e+00],\n",
       "        [ 1.1410e+00,  8.1675e+00, -5.7079e+00, -1.0415e-01,  5.4166e+00,\n",
       "          3.6436e+00,  3.1762e+00, -3.6867e+00,  4.5208e+00, -1.4119e+00,\n",
       "         -6.4104e+00,  7.1894e+00, -2.7314e+00,  5.7877e+00, -4.8640e+00,\n",
       "         -3.9499e-02,  2.0588e+00,  7.6181e+00,  1.0397e+01, -1.3117e+01,\n",
       "          2.2465e+00,  3.8631e-01, -4.3557e+00, -1.1844e+01, -2.5559e+00,\n",
       "         -1.0303e+01,  1.7035e+01],\n",
       "        [-5.8426e+00, -1.5770e+00, -3.7732e+00, -1.9011e+00, -8.2303e-01,\n",
       "         -5.5852e+00, -9.5573e+00, -8.4334e+00, -4.2388e+00, -2.9946e+00,\n",
       "         -7.8972e+00,  9.1407e+00, -8.9179e-02, -7.1405e-02,  3.2678e+00,\n",
       "          3.3024e+00,  6.2037e+00, -6.5526e-01,  1.6849e+01, -1.2014e+01,\n",
       "          1.2151e+01,  1.2352e-01, -1.6049e+01, -8.6607e+00,  1.8375e+00,\n",
       "         -1.6506e+01,  1.3917e+01],\n",
       "        [-4.9579e+00,  8.7886e-01, -4.3165e+00, -2.3336e-01, -2.5653e+00,\n",
       "          4.1896e+00, -1.6088e+01,  1.6396e-01, -4.2350e+00,  6.7536e-01,\n",
       "         -1.3856e+00,  2.0273e-01,  4.7362e-01,  4.7221e+00,  7.5306e+00,\n",
       "         -3.8023e+00,  7.7891e+00, -4.6831e+00,  6.5312e+00, -2.3727e+01,\n",
       "          1.8818e+01,  5.3944e+00, -1.0330e+00, -1.2145e+01,  6.4684e+00,\n",
       "         -5.7222e+00,  1.2398e+01],\n",
       "        [ 2.1722e+00, -3.6600e+00, -4.8765e+00, -7.6700e-01, -4.9400e+00,\n",
       "         -4.1159e+00,  1.3166e+01,  1.1469e-01,  4.3073e+00, -4.8143e+00,\n",
       "          1.1336e+01, -1.2770e+01,  6.1721e+00, -1.2698e+00, -6.1960e+00,\n",
       "         -6.8259e+00, -1.2740e+01,  6.2393e+00, -7.0751e+00,  8.5019e+00,\n",
       "         -1.2288e+01,  3.2109e+00,  3.0172e+00,  5.5729e+00,  1.3722e+00,\n",
       "          1.1352e+01, -3.7329e+00],\n",
       "        [ 9.5867e+00,  7.0132e+00,  1.0619e+01, -5.3117e+00,  8.1650e+00,\n",
       "         -6.3471e-01,  1.4075e+01,  4.1641e+00,  2.1126e+00,  2.1009e+00,\n",
       "          4.4747e+00,  3.4812e-01, -3.1116e+00, -7.1284e+00, -1.2663e+01,\n",
       "         -6.6423e+00, -7.6263e+00,  5.4347e+00, -8.3089e+00,  2.2404e+01,\n",
       "         -2.6677e+01, -4.5250e+00,  1.7367e+00,  1.0894e+01, -4.3878e-01,\n",
       "          4.8994e-01, -1.4953e+01],\n",
       "        [ 1.0339e+01,  8.4039e+00,  4.1276e+00, -8.6811e-01,  7.1198e+00,\n",
       "          2.9675e+00,  1.4469e+01,  6.4403e+00,  5.0844e+00, -8.7127e-01,\n",
       "          2.7792e+00,  1.5937e+00,  3.9959e+00, -4.0004e+00, -9.8303e+00,\n",
       "         -7.4044e+00, -6.0276e+00,  5.1773e+00, -5.7510e+00,  5.1513e+00,\n",
       "         -1.6312e+01,  1.9413e-01,  3.8357e+00,  5.5176e+00, -1.8361e+00,\n",
       "          3.7879e+00, -8.6234e+00],\n",
       "        [ 1.0882e+01,  1.0689e+01,  8.3067e+00, -1.0882e-01,  8.5998e+00,\n",
       "          3.6865e+00,  1.2778e+01,  8.3188e+00,  6.1602e+00, -2.9399e+00,\n",
       "          2.6398e+00,  2.2891e+00, -1.8251e+00, -2.0688e+00, -8.5253e+00,\n",
       "         -5.1564e+00, -4.8787e+00,  8.0808e+00, -3.9176e+00,  6.1599e+00,\n",
       "         -1.2264e+01, -3.5532e+00,  3.3294e+00, -1.9572e+00, -3.0141e+00,\n",
       "         -6.7364e-01, -4.7768e+00],\n",
       "        [ 9.9218e+00,  1.3198e+01,  6.3682e+00,  1.2081e+00,  9.2738e+00,\n",
       "          4.5196e+00,  1.0675e+01,  7.3001e+00,  7.6507e+00, -5.2631e+00,\n",
       "          2.4796e-01,  4.7178e+00, -1.2119e+00,  2.1325e+00, -8.6873e+00,\n",
       "         -2.3159e+00, -3.1426e+00,  7.4567e+00, -2.4287e+00, -2.4219e+00,\n",
       "         -7.0061e+00, -1.7038e+00,  3.6556e+00, -6.4047e+00, -3.1937e+00,\n",
       "         -1.6679e+00,  1.9714e+00],\n",
       "        [ 9.2660e+00,  9.0790e+00,  9.1451e+00, -1.9479e+00,  4.0693e+00,\n",
       "         -1.5904e+00,  7.8220e+00,  7.3149e+00,  7.6845e+00, -3.2260e+00,\n",
       "          4.2336e+00,  3.9021e-01, -3.5303e+00, -3.4869e+00, -4.0507e+00,\n",
       "         -4.4027e+00, -5.3789e+00,  9.7764e+00, -1.9805e+00,  1.5476e+01,\n",
       "         -1.0159e+01, -4.2702e+00, -4.8267e+00, -1.4732e+00, -3.5782e+00,\n",
       "         -4.5758e+00, -5.4682e+00],\n",
       "        [ 5.7502e+00,  1.2987e+01,  1.2106e+01,  3.1571e-01,  1.0249e+01,\n",
       "          3.0537e+00,  6.0257e+00,  7.0335e+00, -4.4390e-01, -1.0795e-01,\n",
       "         -1.9093e+00,  5.4900e+00, -3.9279e+00,  1.6083e+00, -8.2568e+00,\n",
       "         -4.1924e+00,  1.7530e+00,  2.0646e+00,  2.3499e-01, -4.0822e+00,\n",
       "         -9.4845e+00, -2.7879e+00,  5.8070e+00, -6.8237e+00, -5.3603e-01,\n",
       "         -5.8991e+00, -1.6815e+00],\n",
       "        [ 1.0882e+01,  1.0689e+01,  8.3067e+00, -1.0882e-01,  8.5998e+00,\n",
       "          3.6865e+00,  1.2778e+01,  8.3188e+00,  6.1602e+00, -2.9399e+00,\n",
       "          2.6398e+00,  2.2891e+00, -1.8251e+00, -2.0688e+00, -8.5253e+00,\n",
       "         -5.1564e+00, -4.8787e+00,  8.0808e+00, -3.9176e+00,  6.1599e+00,\n",
       "         -1.2264e+01, -3.5532e+00,  3.3294e+00, -1.9572e+00, -3.0141e+00,\n",
       "         -6.7364e-01, -4.7768e+00],\n",
       "        [ 9.6717e+00,  8.8179e+00,  1.1016e+01, -2.0084e+00,  6.3237e+00,\n",
       "          5.3622e-01,  1.1890e+01,  7.8957e+00,  5.4826e+00, -1.3733e+00,\n",
       "          4.7371e+00,  1.1793e+00, -3.0064e+00, -4.7606e+00, -7.9261e+00,\n",
       "         -5.9146e+00, -6.5939e+00,  8.9679e+00, -5.0383e+00,  1.6293e+01,\n",
       "         -1.6166e+01, -4.6035e+00, -3.5524e-01,  1.1021e+00, -2.6639e+00,\n",
       "         -2.0202e+00, -8.9948e+00],\n",
       "        [ 3.3937e+00,  8.9222e+00,  4.3851e+00, -8.6318e-01,  7.4358e+00,\n",
       "          2.7569e+00,  4.9261e+00, -1.3307e+00,  2.4229e+00, -3.5847e-01,\n",
       "         -5.8573e+00,  6.6947e+00, -4.5890e+00,  1.8002e+00, -8.0529e+00,\n",
       "         -9.5247e-01,  9.9728e-01,  6.3546e+00,  4.2731e+00, -3.4220e+00,\n",
       "         -4.9222e+00, -9.8435e-02, -2.6746e+00, -9.7867e+00, -1.4126e+00,\n",
       "         -1.1392e+01,  7.8555e+00],\n",
       "        [-1.6352e+00,  1.6448e+01,  2.8134e+00,  2.0929e+00,  5.4700e+00,\n",
       "          6.4905e-01, -2.6976e+00,  9.3049e+00,  5.3563e+00, -2.4929e+00,\n",
       "         -1.4266e+00,  8.4610e+00,  2.0399e+00,  9.0712e+00,  1.9602e-01,\n",
       "          8.7990e-01,  1.8319e+00,  3.3108e-01,  3.4236e+00, -1.9345e+01,\n",
       "          1.0377e+01,  2.6727e+00, -3.7843e+00, -9.3424e+00, -3.1508e+00,\n",
       "         -9.6240e+00,  9.5214e+00],\n",
       "        [-1.9870e+00,  4.3702e+00, -1.3947e+01,  5.5458e+00, -1.5760e+00,\n",
       "          4.5683e+00, -9.9090e-01, -1.7168e+00,  1.5377e+01, -4.0733e+00,\n",
       "         -5.9881e-01, -2.3559e+00, -1.2177e+00,  9.8149e+00,  3.3133e+00,\n",
       "          5.6569e+00,  1.0241e+00,  6.7141e+00,  9.0943e+00, -2.8746e+01,\n",
       "          1.4495e+01,  1.6545e+00, -7.6810e+00, -1.3600e+01,  7.0196e-01,\n",
       "         -3.4012e+00,  2.1791e+01],\n",
       "        [ 3.0467e+00,  1.2321e+01,  3.7614e+00, -2.2909e+00,  7.2528e+00,\n",
       "          1.5812e+00, -1.6722e+00,  3.0019e+00,  1.5752e+00, -1.7445e+00,\n",
       "         -4.4701e+00,  4.4602e+00, -6.8906e+00,  2.9891e+00, -1.2105e+00,\n",
       "         -1.5626e+00,  5.4118e+00,  1.6034e+00,  7.1318e+00, -8.5492e+00,\n",
       "          2.9487e+00, -2.6805e+00, -3.9263e+00, -1.1421e+01,  2.1947e+00,\n",
       "         -1.2360e+01,  9.2830e+00],\n",
       "        [-9.4061e+00, -4.5406e+00, -5.9791e+00, -2.1050e+00, -3.6797e+00,\n",
       "         -1.4646e+00, -3.2565e+00, -1.1088e+01, -1.8141e+00, -1.9307e+00,\n",
       "         -2.2427e+00, -1.8415e+00, -3.6772e+00, -1.0360e+00, -9.9916e-01,\n",
       "          1.3197e+00,  3.1963e-01,  3.3594e+00,  7.9632e+00, -7.2673e+00,\n",
       "          4.4724e+00,  2.4976e+00, -9.3962e+00, -6.8438e+00,  4.1481e+00,\n",
       "         -8.6143e+00,  1.0818e+01],\n",
       "        [-9.8354e+00, -7.6004e+00,  1.4579e+00, -2.0887e+00, -2.3856e+00,\n",
       "         -3.8077e+00, -1.2454e+01, -1.2826e+01, -8.3028e+00,  1.6277e+00,\n",
       "         -7.0305e+00,  6.4951e+00, -1.3806e+00, -5.1967e+00,  2.7463e+00,\n",
       "          1.5558e+00,  5.3750e+00, -3.9504e+00,  1.0676e+01, -4.5007e+00,\n",
       "          7.5278e+00,  3.7965e+00, -1.2308e+01, -3.1373e+00,  8.7655e+00,\n",
       "         -1.6065e+01,  4.8479e+00],\n",
       "        [-1.1019e+01,  2.2267e+00, -3.6807e+00, -3.9650e+00, -3.0092e+00,\n",
       "          3.5721e+00, -1.3533e+01,  2.3020e+00,  7.4351e-01, -8.5942e-01,\n",
       "          1.7935e+00, -6.2694e-01,  9.4932e+00,  1.1410e+01,  3.3204e+00,\n",
       "         -1.7388e+00,  4.2824e+00, -5.9350e+00,  2.9235e+00, -2.3858e+01,\n",
       "          1.8765e+01,  5.9127e+00, -5.7877e-01, -5.6622e+00,  7.7995e+00,\n",
       "         -7.5935e-02,  9.1636e+00],\n",
       "        [ 1.0882e+01,  1.0689e+01,  8.3067e+00, -1.0882e-01,  8.5998e+00,\n",
       "          3.6865e+00,  1.2778e+01,  8.3188e+00,  6.1602e+00, -2.9399e+00,\n",
       "          2.6398e+00,  2.2891e+00, -1.8251e+00, -2.0688e+00, -8.5253e+00,\n",
       "         -5.1564e+00, -4.8787e+00,  8.0808e+00, -3.9176e+00,  6.1599e+00,\n",
       "         -1.2264e+01, -3.5532e+00,  3.3294e+00, -1.9572e+00, -3.0141e+00,\n",
       "         -6.7364e-01, -4.7768e+00],\n",
       "        [ 4.5092e+00,  1.0386e+01, -1.8503e+00, -1.2576e+00,  6.9023e+00,\n",
       "          2.6823e+00,  5.7607e+00, -1.5489e+00,  6.6794e+00, -3.2339e+00,\n",
       "         -4.8015e+00,  5.9024e+00, -2.6994e+00,  5.6181e+00, -6.7820e+00,\n",
       "         -6.0842e-01,  4.5365e-01,  8.3226e+00,  6.0395e+00, -7.6743e+00,\n",
       "         -5.5043e-01,  3.1001e-01, -2.7800e+00, -1.1047e+01, -3.0278e+00,\n",
       "         -8.4153e+00,  1.4387e+01],\n",
       "        [-6.7054e+00,  4.1728e+00, -6.3617e+00,  4.2667e+00, -1.1653e+00,\n",
       "          1.4103e+00, -1.3663e+01, -2.3717e+00, -1.7876e+00, -3.5679e+00,\n",
       "         -7.7335e+00,  1.1994e+01,  3.2516e-01,  4.7347e+00,  5.1096e+00,\n",
       "          4.2598e+00,  7.6745e+00, -2.1726e+00,  1.6776e+01, -2.5778e+01,\n",
       "          1.7318e+01,  1.7062e+00, -1.0781e+01, -1.0796e+01,  1.0145e-01,\n",
       "         -1.0768e+01,  1.4852e+01],\n",
       "        [-1.7725e+00,  3.3356e+00, -4.3409e+00,  1.7151e+00, -3.0175e+00,\n",
       "          1.5205e+00, -1.0599e+01,  5.4216e+00,  3.5537e+00, -5.0964e-01,\n",
       "          2.0535e+00, -2.8747e-01,  2.9215e-01,  2.7052e+00,  8.5043e+00,\n",
       "         -8.4710e-01,  2.1687e+00, -4.6220e-01,  7.5262e+00, -2.0585e+01,\n",
       "          1.9533e+01,  3.3557e+00, -5.0574e+00, -1.0045e+01,  6.9281e+00,\n",
       "         -2.3663e+00,  1.1638e+01],\n",
       "        [-1.3643e+01, -2.1276e+00, -7.2805e+00,  4.9166e+00, -4.3991e+00,\n",
       "          5.0702e+00, -7.3085e+00, -1.0195e+01,  1.3878e+00,  6.6803e-01,\n",
       "         -1.1077e+00, -7.1584e-01, -3.4938e+00,  4.7319e+00,  2.0379e+00,\n",
       "          3.4434e+00,  5.2841e+00,  1.3963e+00,  7.4587e+00, -2.2324e+01,\n",
       "          1.1685e+01,  4.6705e+00, -6.1510e+00, -1.3973e+01,  3.1387e+00,\n",
       "         -4.8968e+00,  1.5944e+01],\n",
       "        [ 4.0813e+00,  7.8589e+00,  8.5866e+00, -3.0822e+00,  4.9418e+00,\n",
       "         -6.1224e+00,  1.1557e-01,  9.1430e+00, -6.9366e-01, -1.5793e+00,\n",
       "          5.8921e-01,  5.4035e+00,  3.5207e+00, -9.0581e-01,  3.2375e+00,\n",
       "         -2.7795e+00,  3.5320e+00, -1.4749e+00,  5.7483e+00, -1.0093e+00,\n",
       "          4.1470e+00, -1.2687e+00, -7.1194e+00,  9.5636e-01,  8.6115e-01,\n",
       "         -1.2760e+01, -4.0528e+00],\n",
       "        [-6.1833e+00,  3.3727e+00, -6.4253e+00,  4.5346e+00, -3.1136e+00,\n",
       "          8.5532e+00, -4.1459e+00,  1.5225e+00,  1.1365e+01, -2.7946e-01,\n",
       "          5.6856e+00, -2.9552e+00,  5.8081e+00,  1.0790e+01,  1.8737e+00,\n",
       "         -3.1103e+00, -4.2221e-01,  2.8418e+00, -7.9927e-01, -2.7427e+01,\n",
       "          1.5788e+01,  4.9203e+00,  3.3511e-01, -1.0426e+01,  5.2701e+00,\n",
       "          5.8096e+00,  1.3760e+01]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:40:15.402967Z",
     "start_time": "2025-07-11T18:40:15.392797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counts = logits.exp()\n",
    "counts"
   ],
   "id": "46cf1d9989e43dbb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3227e+04, 4.3853e+04, 4.0510e+03, 8.9689e-01, 5.4303e+03, 3.9905e+01,\n",
       "         3.5451e+05, 4.1001e+03, 4.7354e+02, 5.2873e-02, 1.4010e+01, 9.8656e+00,\n",
       "         1.6120e-01, 1.2634e-01, 1.9838e-04, 5.7621e-03, 7.6072e-03, 3.2319e+03,\n",
       "         1.9889e-02, 4.7338e+02, 4.7183e-06, 2.8632e-02, 2.7922e+01, 1.4125e-01,\n",
       "         4.9088e-02, 5.0985e-01, 8.4226e-03],\n",
       "        [7.4589e+03, 1.0468e+04, 1.4239e+04, 1.7694e-01, 4.0054e+02, 2.1292e+00,\n",
       "         2.3507e+04, 1.5471e+02, 1.4711e+03, 7.0230e-02, 1.8863e+01, 5.1782e+00,\n",
       "         1.5244e-02, 3.5080e-02, 8.0545e-04, 1.0437e-02, 4.3271e-03, 1.5510e+04,\n",
       "         3.0197e-02, 6.3938e+05, 6.0106e-06, 3.2934e-02, 6.9194e-02, 1.4247e-01,\n",
       "         5.2949e-02, 1.1701e-02, 2.2251e-02],\n",
       "        [1.4360e+04, 4.5201e+03, 3.3555e+05, 4.3567e-04, 2.9434e+03, 1.7553e-01,\n",
       "         4.9181e+03, 4.5895e+02, 3.5027e+01, 1.9330e+00, 2.9964e+01, 3.4942e+00,\n",
       "         2.9473e-03, 1.9847e-03, 1.4939e-04, 3.9163e-04, 2.1645e-02, 7.6004e+02,\n",
       "         1.9085e-03, 5.8566e+09, 6.2305e-11, 2.0666e-03, 7.3209e-01, 1.3431e+02,\n",
       "         7.9803e-02, 3.4729e-03, 5.9201e-06],\n",
       "        [4.4332e+03, 4.2104e+01, 5.0769e+04, 1.2995e-03, 1.3257e+03, 8.7154e-02,\n",
       "         6.9932e+05, 1.4736e+01, 1.0068e+01, 4.1929e+00, 1.2833e+02, 1.8570e-01,\n",
       "         1.7815e-02, 3.7899e-04, 1.2923e-06, 1.4086e-03, 9.5876e-05, 1.8634e+02,\n",
       "         9.4120e-05, 1.6621e+11, 1.6651e-13, 1.3461e-02, 9.6065e+00, 8.5842e+04,\n",
       "         2.9785e+00, 5.4824e+00, 8.3821e-08],\n",
       "        [2.5516e+04, 1.6744e+03, 1.7284e+03, 3.2723e-01, 9.9820e+02, 1.3703e+01,\n",
       "         2.3435e+06, 3.5581e+01, 4.9918e+00, 1.2044e+01, 2.8598e+01, 5.4067e+00,\n",
       "         1.3328e+00, 6.4786e-04, 3.1529e-05, 1.6528e-03, 3.6350e-03, 3.4671e+01,\n",
       "         2.4857e-03, 6.6281e+04, 3.5722e-09, 1.0236e+00, 1.4841e+01, 5.5618e+04,\n",
       "         3.5160e-01, 4.6367e+01, 8.9982e-07],\n",
       "        [5.3227e+04, 4.3853e+04, 4.0510e+03, 8.9689e-01, 5.4303e+03, 3.9905e+01,\n",
       "         3.5451e+05, 4.1001e+03, 4.7354e+02, 5.2873e-02, 1.4010e+01, 9.8656e+00,\n",
       "         1.6120e-01, 1.2634e-01, 1.9838e-04, 5.7621e-03, 7.6072e-03, 3.2319e+03,\n",
       "         1.9889e-02, 4.7338e+02, 4.7183e-06, 2.8632e-02, 2.7922e+01, 1.4125e-01,\n",
       "         4.9088e-02, 5.0985e-01, 8.4226e-03],\n",
       "        [3.1299e+00, 3.5245e+03, 3.3196e-03, 9.0109e-01, 2.2512e+02, 3.8230e+01,\n",
       "         2.3956e+01, 2.5055e-02, 9.1906e+01, 2.4368e-01, 1.6444e-03, 1.3253e+03,\n",
       "         6.5128e-02, 3.2625e+02, 7.7199e-03, 9.6127e-01, 7.8363e+00, 2.0347e+03,\n",
       "         3.2768e+04, 2.0111e-06, 9.4546e+00, 1.4715e+00, 1.2833e-02, 7.1835e-06,\n",
       "         7.7626e-02, 3.3520e-05, 2.5020e+07],\n",
       "        [2.9012e-03, 2.0659e-01, 2.2979e-02, 1.4940e-01, 4.3910e-01, 3.7531e-03,\n",
       "         7.0682e-05, 2.1749e-04, 1.4425e-02, 5.0058e-02, 3.7178e-04, 9.3272e+03,\n",
       "         9.1468e-01, 9.3108e-01, 2.6255e+01, 2.7177e+01, 4.9455e+02, 5.1931e-01,\n",
       "         2.0761e+07, 6.0558e-06, 1.8923e+05, 1.1315e+00, 1.0714e-07, 1.7327e-04,\n",
       "         6.2808e+00, 6.7854e-08, 1.1067e+06],\n",
       "        [7.0280e-03, 2.4081e+00, 1.3346e-02, 7.9187e-01, 7.6899e-02, 6.5994e+01,\n",
       "         1.0310e-07, 1.1782e+00, 1.4480e-02, 1.9647e+00, 2.5017e-01, 1.2247e+00,\n",
       "         1.6058e+00, 1.1240e+02, 1.8643e+03, 2.2319e-02, 2.4141e+03, 9.2507e-03,\n",
       "         6.8624e+02, 4.9589e-11, 1.4884e+08, 2.2018e+02, 3.5593e-01, 5.3168e-06,\n",
       "         6.4443e+02, 3.2725e-03, 2.4227e+05],\n",
       "        [8.7773e+00, 2.5732e-02, 7.6234e-03, 4.6440e-01, 7.1546e-03, 1.6311e-02,\n",
       "         5.2210e+05, 1.1215e+00, 7.4240e+01, 8.1126e-03, 8.3800e+04, 2.8456e-06,\n",
       "         4.7918e+02, 2.8088e-01, 2.0375e-03, 1.0853e-03, 2.9323e-06, 5.1251e+02,\n",
       "         8.4591e-04, 4.9241e+03, 4.6046e-06, 2.4802e+01, 2.0434e+01, 2.6320e+02,\n",
       "         3.9439e+00, 8.5139e+04, 2.3924e-02],\n",
       "        [1.4569e+04, 1.1112e+03, 4.0903e+04, 4.9336e-03, 3.5158e+03, 5.3009e-01,\n",
       "         1.2959e+06, 6.4333e+01, 8.2696e+00, 8.1739e+00, 8.7766e+01, 1.4164e+00,\n",
       "         4.4528e-02, 8.0204e-04, 3.1647e-06, 1.3040e-03, 4.8746e-04, 2.2922e+02,\n",
       "         2.4630e-04, 5.3709e+09, 2.5974e-12, 1.0835e-02, 5.6785e+00, 5.3832e+04,\n",
       "         6.4482e-01, 1.6322e+00, 3.2048e-07],\n",
       "        [3.0926e+04, 4.4645e+03, 6.2028e+01, 4.1974e-01, 1.2362e+03, 1.9444e+01,\n",
       "         1.9217e+06, 6.2659e+02, 1.6148e+02, 4.1842e-01, 1.6106e+01, 4.9218e+00,\n",
       "         5.4374e+01, 1.8309e-02, 5.3797e-05, 6.0854e-04, 2.4112e-03, 1.7720e+02,\n",
       "         3.1797e-03, 1.7266e+02, 8.2348e-08, 1.2142e+00, 4.6324e+01, 2.4902e+02,\n",
       "         1.5944e-01, 4.4161e+01, 1.7985e-04],\n",
       "        [5.3227e+04, 4.3853e+04, 4.0510e+03, 8.9689e-01, 5.4303e+03, 3.9905e+01,\n",
       "         3.5451e+05, 4.1001e+03, 4.7354e+02, 5.2873e-02, 1.4010e+01, 9.8656e+00,\n",
       "         1.6120e-01, 1.2634e-01, 1.9838e-04, 5.7621e-03, 7.6072e-03, 3.2319e+03,\n",
       "         1.9889e-02, 4.7338e+02, 4.7183e-06, 2.8632e-02, 2.7922e+01, 1.4125e-01,\n",
       "         4.9088e-02, 5.0985e-01, 8.4226e-03],\n",
       "        [2.0369e+04, 5.3918e+05, 5.8303e+02, 3.3470e+00, 1.0655e+04, 9.1799e+01,\n",
       "         4.3241e+04, 1.4804e+03, 2.1022e+03, 5.1793e-03, 1.2814e+00, 1.1192e+02,\n",
       "         2.9764e-01, 8.4358e+00, 1.6871e-04, 9.8677e-02, 4.3172e-02, 1.7315e+03,\n",
       "         8.8147e-02, 8.8750e-02, 9.0636e-04, 1.8199e-01, 3.8689e+01, 1.6537e-03,\n",
       "         4.1021e-02, 1.8865e-01, 7.1808e+00],\n",
       "        [1.0573e+04, 8.7690e+03, 9.3683e+03, 1.4258e-01, 5.8516e+01, 2.0385e-01,\n",
       "         2.4948e+03, 1.5026e+03, 2.1744e+03, 3.9716e-02, 6.8968e+01, 1.4773e+00,\n",
       "         2.9295e-02, 3.0595e-02, 1.7410e-02, 1.2245e-02, 4.6127e-03, 1.7613e+04,\n",
       "         1.3800e-01, 5.2642e+06, 3.8712e-05, 1.3978e-02, 8.0129e-03, 2.2919e-01,\n",
       "         2.7925e-02, 1.0298e-02, 4.2187e-03],\n",
       "        [3.1425e+02, 4.3687e+05, 1.8104e+05, 1.3712e+00, 2.8240e+04, 2.1194e+01,\n",
       "         4.1393e+02, 1.1339e+03, 6.4153e-01, 8.9767e-01, 1.4818e-01, 2.4226e+02,\n",
       "         1.9685e-02, 4.9943e+00, 2.5948e-04, 1.5111e-02, 5.7717e+00, 7.8818e+00,\n",
       "         1.2649e+00, 1.6871e-02, 7.6022e-05, 6.1553e-02, 3.3263e+02, 1.0877e-03,\n",
       "         5.8506e-01, 2.7419e-03, 1.8609e-01],\n",
       "        [5.3227e+04, 4.3853e+04, 4.0510e+03, 8.9689e-01, 5.4303e+03, 3.9905e+01,\n",
       "         3.5451e+05, 4.1001e+03, 4.7354e+02, 5.2873e-02, 1.4010e+01, 9.8656e+00,\n",
       "         1.6120e-01, 1.2634e-01, 1.9838e-04, 5.7621e-03, 7.6072e-03, 3.2319e+03,\n",
       "         1.9889e-02, 4.7338e+02, 4.7183e-06, 2.8632e-02, 2.7922e+01, 1.4125e-01,\n",
       "         4.9088e-02, 5.0985e-01, 8.4226e-03],\n",
       "        [1.5863e+04, 6.7540e+03, 6.0836e+04, 1.3420e-01, 5.5764e+02, 1.7095e+00,\n",
       "         1.4575e+05, 2.6857e+03, 2.4047e+02, 2.5327e-01, 1.1410e+02, 3.2520e+00,\n",
       "         4.9470e-02, 8.5606e-03, 3.6121e-04, 2.6998e-03, 1.3687e-03, 7.8470e+03,\n",
       "         6.4847e-03, 1.1911e+07, 9.5341e-08, 1.0016e-02, 7.0101e-01, 3.0105e+00,\n",
       "         6.9674e-02, 1.3263e-01, 1.2405e-04],\n",
       "        [2.9775e+01, 7.4963e+03, 8.0249e+01, 4.2182e-01, 1.6955e+03, 1.5751e+01,\n",
       "         1.3785e+02, 2.6428e-01, 1.1278e+01, 6.9875e-01, 2.8588e-03, 8.0810e+02,\n",
       "         1.0163e-02, 6.0506e+00, 3.1818e-04, 3.8579e-01, 2.7109e+00, 5.7515e+02,\n",
       "         7.1747e+01, 3.2646e-02, 7.2832e-03, 9.0625e-01, 6.8936e-02, 5.6196e-05,\n",
       "         2.4351e-01, 1.1284e-05, 2.5798e+03],\n",
       "        [1.9492e-01, 1.3911e+07, 1.6666e+01, 8.1081e+00, 2.3746e+02, 1.9137e+00,\n",
       "         6.7366e-02, 1.0992e+04, 2.1195e+02, 8.2669e-02, 2.4011e-01, 4.7269e+03,\n",
       "         7.6898e+00, 8.7014e+03, 1.2165e+00, 2.4107e+00, 6.2459e+00, 1.3925e+00,\n",
       "         3.0678e+01, 3.9681e-09, 3.2102e+04, 1.4479e+01, 2.2724e-02, 8.7630e-05,\n",
       "         4.2819e-02, 6.6123e-05, 1.3649e+04],\n",
       "        [1.3710e-01, 7.9057e+01, 8.7668e-07, 2.5616e+02, 2.0680e-01, 9.6382e+01,\n",
       "         3.7124e-01, 1.7965e-01, 4.7659e+06, 1.7021e-02, 5.4947e-01, 9.4808e-02,\n",
       "         2.9592e-01, 1.8304e+04, 2.7476e+01, 2.8627e+02, 2.7847e+00, 8.2394e+02,\n",
       "         8.9045e+03, 3.2788e-13, 1.9723e+06, 5.2305e+00, 4.6151e-04, 1.2411e-06,\n",
       "         2.0177e+00, 3.3334e-02, 2.9088e+09],\n",
       "        [2.1046e+01, 2.2428e+05, 4.3008e+01, 1.0118e-01, 1.4121e+03, 4.8606e+00,\n",
       "         1.8783e-01, 2.0124e+01, 4.8318e+00, 1.7474e-01, 1.1446e-02, 8.6508e+01,\n",
       "         1.0173e-03, 1.9867e+01, 2.9805e-01, 2.0958e-01, 2.2404e+02, 4.9700e+00,\n",
       "         1.2512e+03, 1.9370e-04, 1.9081e+01, 6.8530e-02, 1.9716e-02, 1.0962e-05,\n",
       "         8.9776e+00, 4.2852e-06, 1.0754e+04],\n",
       "        [8.2223e-05, 1.0667e-02, 2.5311e-03, 1.2184e-01, 2.5230e-02, 2.3116e-01,\n",
       "         3.8524e-02, 1.5292e-05, 1.6299e-01, 1.4505e-01, 1.0617e-01, 1.5857e-01,\n",
       "         2.5294e-02, 3.5487e-01, 3.6819e-01, 3.7422e+00, 1.3766e+00, 2.8771e+01,\n",
       "         2.8733e+03, 6.9801e-04, 8.7566e+01, 1.2153e+01, 8.3037e-05, 1.0660e-03,\n",
       "         6.3311e+01, 1.8149e-04, 4.9924e+04],\n",
       "        [5.3521e-05, 5.0025e-04, 4.2971e+00, 1.2384e-01, 9.2033e-02, 2.2198e-02,\n",
       "         3.9015e-06, 2.6906e-06, 2.4781e-04, 5.0924e+00, 8.8446e-04, 6.6189e+02,\n",
       "         2.5143e-01, 5.5347e-03, 1.5585e+01, 4.7387e+00, 2.1594e+02, 1.9247e-02,\n",
       "         4.3307e+04, 1.1101e-02, 1.8590e+03, 4.4546e+01, 4.5136e-06, 4.3402e-02,\n",
       "         6.4092e+03, 1.0548e-07, 1.2747e+02],\n",
       "        [1.6386e-05, 9.2696e+00, 2.5206e-02, 1.8968e-02, 4.9333e-02, 3.5593e+01,\n",
       "         1.3262e-06, 9.9941e+00, 2.1033e+00, 4.2341e-01, 6.0102e+00, 5.3422e-01,\n",
       "         1.3269e+04, 9.0193e+04, 2.7672e+01, 1.7573e-01, 7.2417e+01, 2.6453e-03,\n",
       "         1.8606e+01, 4.3516e-11, 1.4112e+08, 3.6972e+02, 5.6059e-01, 3.4750e-03,\n",
       "         2.4394e+03, 9.2688e-01, 9.5434e+03],\n",
       "        [5.3227e+04, 4.3853e+04, 4.0510e+03, 8.9689e-01, 5.4303e+03, 3.9905e+01,\n",
       "         3.5451e+05, 4.1001e+03, 4.7354e+02, 5.2873e-02, 1.4010e+01, 9.8656e+00,\n",
       "         1.6120e-01, 1.2634e-01, 1.9838e-04, 5.7621e-03, 7.6072e-03, 3.2319e+03,\n",
       "         1.9889e-02, 4.7338e+02, 4.7183e-06, 2.8632e-02, 2.7922e+01, 1.4125e-01,\n",
       "         4.9088e-02, 5.0985e-01, 8.4226e-03],\n",
       "        [9.0848e+01, 3.2400e+04, 1.5719e-01, 2.8435e-01, 9.9455e+02, 1.4619e+01,\n",
       "         3.1757e+02, 2.1247e-01, 7.9587e+02, 3.9403e-02, 8.2175e-03, 3.6590e+02,\n",
       "         6.7248e-02, 2.7536e+02, 1.1340e-03, 5.4421e-01, 1.5740e+00, 4.1160e+03,\n",
       "         4.1967e+02, 4.6459e-04, 5.7670e-01, 1.3634e+00, 6.2039e-02, 1.5941e-05,\n",
       "         4.8422e-02, 2.2145e-04, 1.7712e+06],\n",
       "        [1.2243e-03, 6.4899e+01, 1.7264e-03, 7.1289e+01, 3.1182e-01, 4.0974e+00,\n",
       "         1.1648e-06, 9.3320e-02, 1.6737e-01, 2.8215e-02, 4.3791e-04, 1.6183e+05,\n",
       "         1.3843e+00, 1.1383e+02, 1.6561e+02, 7.0798e+01, 2.1526e+03, 1.1389e-01,\n",
       "         1.9316e+07, 6.3819e-12, 3.3196e+07, 5.5080e+00, 2.0797e-05, 2.0487e-05,\n",
       "         1.1068e+00, 2.1069e-05, 2.8183e+06],\n",
       "        [1.6991e-01, 2.8096e+01, 1.3025e-02, 5.5573e+00, 4.8924e-02, 4.5744e+00,\n",
       "         2.4940e-05, 2.2624e+02, 3.4942e+01, 6.0071e-01, 7.7953e+00, 7.5016e-01,\n",
       "         1.3393e+00, 1.4957e+01, 4.9357e+03, 4.2866e-01, 8.7473e+00, 6.2990e-01,\n",
       "         1.8561e+03, 1.1488e-09, 3.0414e+08, 2.8665e+01, 6.3619e-03, 4.3381e-05,\n",
       "         1.0206e+03, 9.3830e-02, 1.1327e+05],\n",
       "        [1.1885e-06, 1.1912e-01, 6.8881e-04, 1.3654e+02, 1.2288e-02, 1.5920e+02,\n",
       "         6.6979e-04, 3.7348e-05, 4.0059e+00, 1.9504e+00, 3.3032e-01, 4.8878e-01,\n",
       "         3.0385e-02, 1.1352e+02, 7.6741e+00, 3.1292e+01, 1.9717e+02, 4.0403e+00,\n",
       "         1.7350e+03, 2.0172e-10, 1.1876e+05, 1.0675e+02, 2.1313e-03, 8.5420e-07,\n",
       "         2.3074e+01, 7.4701e-03, 8.4038e+06],\n",
       "        [5.9224e+01, 2.5887e+03, 5.3592e+03, 4.5858e-02, 1.4003e+02, 2.1932e-03,\n",
       "         1.1225e+00, 9.3485e+03, 4.9974e-01, 2.0613e-01, 1.8026e+00, 2.2219e+02,\n",
       "         3.3807e+01, 4.0421e-01, 2.5469e+01, 6.2072e-02, 3.4191e+01, 2.2880e-01,\n",
       "         3.1366e+02, 3.6449e-01, 6.3245e+01, 2.8120e-01, 8.0927e-04, 2.6022e+00,\n",
       "         2.3659e+00, 2.8742e-06, 1.7373e-02],\n",
       "        [2.0637e-03, 2.9157e+01, 1.6201e-03, 9.3183e+01, 4.4443e-02, 5.1834e+03,\n",
       "         1.5829e-02, 4.5836e+00, 8.6226e+04, 7.5619e-01, 2.9460e+02, 5.2070e-02,\n",
       "         3.3299e+02, 4.8517e+04, 6.5127e+00, 4.4586e-02, 6.5560e-01, 1.7147e+01,\n",
       "         4.4966e-01, 1.2261e-12, 7.1882e+06, 1.3704e+02, 1.3981e+00, 2.9649e-05,\n",
       "         1.9443e+02, 3.3350e+02, 9.4596e+05]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:41:32.047240Z",
     "start_time": "2025-07-11T18:41:32.036855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "probs  = counts/counts.sum(1, keepdims = True )\n",
    "probs"
   ],
   "id": "a52434184c6df994",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1338e-01, 9.3415e-02, 8.6294e-03, 1.9105e-06, 1.1567e-02, 8.5004e-05,\n",
       "         7.5517e-01, 8.7340e-03, 1.0087e-03, 1.1263e-07, 2.9845e-05, 2.1015e-05,\n",
       "         3.4339e-07, 2.6912e-07, 4.2258e-10, 1.2274e-08, 1.6205e-08, 6.8845e-03,\n",
       "         4.2366e-08, 1.0084e-03, 1.0051e-11, 6.0991e-08, 5.9479e-05, 3.0089e-07,\n",
       "         1.0457e-07, 1.0861e-06, 1.7942e-08],\n",
       "        [1.0467e-02, 1.4690e-02, 1.9981e-02, 2.4829e-07, 5.6207e-04, 2.9879e-06,\n",
       "         3.2988e-02, 2.1711e-04, 2.0643e-03, 9.8553e-08, 2.6470e-05, 7.2664e-06,\n",
       "         2.1391e-08, 4.9227e-08, 1.1303e-09, 1.4646e-08, 6.0722e-09, 2.1765e-02,\n",
       "         4.2376e-08, 8.9723e-01, 8.4346e-12, 4.6216e-08, 9.7099e-08, 1.9992e-07,\n",
       "         7.4302e-08, 1.6420e-08, 3.1224e-08],\n",
       "        [2.4517e-06, 7.7174e-07, 5.7290e-05, 7.4385e-14, 5.0254e-07, 2.9968e-11,\n",
       "         8.3970e-07, 7.8360e-08, 5.9803e-09, 3.3004e-10, 5.1160e-09, 5.9659e-10,\n",
       "         5.0320e-13, 3.3886e-13, 2.5506e-14, 6.6866e-14, 3.6956e-12, 1.2977e-07,\n",
       "         3.2585e-13, 9.9994e-01, 1.0638e-20, 3.5284e-13, 1.2499e-10, 2.2931e-08,\n",
       "         1.3625e-11, 5.9295e-13, 1.0108e-15],\n",
       "        [2.6672e-08, 2.5331e-10, 3.0545e-07, 7.8185e-15, 7.9759e-09, 5.2436e-13,\n",
       "         4.2074e-06, 8.8659e-11, 6.0574e-11, 2.5226e-11, 7.7208e-10, 1.1172e-12,\n",
       "         1.0718e-13, 2.2802e-15, 7.7753e-18, 8.4746e-15, 5.7683e-16, 1.1211e-09,\n",
       "         5.6626e-16, 9.9999e-01, 1.0018e-24, 8.0987e-14, 5.7797e-11, 5.1646e-07,\n",
       "         1.7920e-11, 3.2984e-11, 5.0430e-19],\n",
       "        [1.0225e-02, 6.7097e-04, 6.9262e-04, 1.3113e-07, 4.0000e-04, 5.4912e-06,\n",
       "         9.3908e-01, 1.4258e-05, 2.0003e-06, 4.8262e-06, 1.1460e-05, 2.1666e-06,\n",
       "         5.3410e-07, 2.5961e-10, 1.2634e-11, 6.6231e-10, 1.4566e-09, 1.3894e-05,\n",
       "         9.9608e-10, 2.6560e-02, 1.4315e-15, 4.1016e-07, 5.9472e-06, 2.2287e-02,\n",
       "         1.4089e-07, 1.8581e-05, 3.6058e-13],\n",
       "        [1.1338e-01, 9.3415e-02, 8.6294e-03, 1.9105e-06, 1.1567e-02, 8.5004e-05,\n",
       "         7.5517e-01, 8.7340e-03, 1.0087e-03, 1.1263e-07, 2.9845e-05, 2.1015e-05,\n",
       "         3.4339e-07, 2.6912e-07, 4.2258e-10, 1.2274e-08, 1.6205e-08, 6.8845e-03,\n",
       "         4.2366e-08, 1.0084e-03, 1.0051e-11, 6.0991e-08, 5.9479e-05, 3.0089e-07,\n",
       "         1.0457e-07, 1.0861e-06, 1.7942e-08],\n",
       "        [1.2489e-07, 1.4064e-04, 1.3246e-10, 3.5957e-08, 8.9832e-06, 1.5255e-06,\n",
       "         9.5592e-07, 9.9980e-10, 3.6674e-06, 9.7236e-09, 6.5617e-11, 5.2887e-05,\n",
       "         2.5989e-09, 1.3019e-05, 3.0805e-10, 3.8358e-08, 3.1270e-07, 8.1191e-05,\n",
       "         1.3076e-03, 8.0251e-14, 3.7727e-07, 5.8720e-08, 5.1210e-10, 2.8665e-13,\n",
       "         3.0976e-09, 1.3376e-12, 9.9839e-01],\n",
       "        [1.3148e-10, 9.3621e-09, 1.0414e-09, 6.7706e-09, 1.9899e-08, 1.7008e-10,\n",
       "         3.2031e-12, 9.8560e-12, 6.5369e-10, 2.2685e-09, 1.6848e-11, 4.2268e-04,\n",
       "         4.1451e-08, 4.2194e-08, 1.1898e-06, 1.2316e-06, 2.2412e-05, 2.3534e-08,\n",
       "         9.4082e-01, 2.7443e-13, 8.5756e-03, 5.1275e-08, 4.8551e-15, 7.8520e-12,\n",
       "         2.8463e-07, 3.0749e-15, 5.0152e-02],\n",
       "        [4.7139e-11, 1.6152e-08, 8.9516e-11, 5.3113e-09, 5.1578e-10, 4.4264e-07,\n",
       "         6.9152e-16, 7.9023e-09, 9.7121e-11, 1.3178e-08, 1.6780e-09, 8.2147e-09,\n",
       "         1.0770e-08, 7.5392e-07, 1.2504e-05, 1.4970e-10, 1.6192e-05, 6.2047e-11,\n",
       "         4.6028e-06, 3.3261e-19, 9.9833e-01, 1.4768e-06, 2.3873e-09, 3.5661e-14,\n",
       "         4.3224e-06, 2.1950e-11, 1.6250e-03],\n",
       "        [1.2587e-05, 3.6899e-08, 1.0932e-08, 6.6596e-07, 1.0260e-08, 2.3391e-08,\n",
       "         7.4869e-01, 1.6083e-06, 1.0646e-04, 1.1633e-08, 1.2017e-01, 4.0806e-12,\n",
       "         6.8714e-04, 4.0278e-07, 2.9218e-09, 1.5563e-09, 4.2049e-12, 7.3495e-04,\n",
       "         1.2130e-09, 7.0612e-03, 6.6030e-12, 3.5566e-05, 2.9302e-05, 3.7743e-04,\n",
       "         5.6555e-06, 1.2209e-01, 3.4307e-08],\n",
       "        [2.7119e-06, 2.0684e-07, 7.6138e-06, 9.1835e-13, 6.5444e-07, 9.8671e-11,\n",
       "         2.4122e-04, 1.1975e-08, 1.5393e-09, 1.5215e-09, 1.6337e-08, 2.6365e-10,\n",
       "         8.2885e-12, 1.4929e-13, 5.8908e-16, 2.4273e-13, 9.0736e-14, 4.2666e-08,\n",
       "         4.5847e-14, 9.9974e-01, 4.8348e-22, 2.0168e-12, 1.0570e-09, 1.0020e-05,\n",
       "         1.2003e-10, 3.0382e-10, 5.9654e-17],\n",
       "        [1.5779e-02, 2.2779e-03, 3.1648e-05, 2.1416e-07, 6.3071e-04, 9.9205e-06,\n",
       "         9.8048e-01, 3.1969e-04, 8.2391e-05, 2.1348e-07, 8.2177e-06, 2.5112e-06,\n",
       "         2.7742e-05, 9.3416e-09, 2.7448e-11, 3.1048e-10, 1.2302e-09, 9.0409e-05,\n",
       "         1.6223e-09, 8.8092e-05, 4.2015e-14, 6.1953e-07, 2.3635e-05, 1.2706e-04,\n",
       "         8.1346e-08, 2.2532e-05, 9.1763e-11],\n",
       "        [1.1338e-01, 9.3415e-02, 8.6294e-03, 1.9105e-06, 1.1567e-02, 8.5004e-05,\n",
       "         7.5517e-01, 8.7340e-03, 1.0087e-03, 1.1263e-07, 2.9845e-05, 2.1015e-05,\n",
       "         3.4339e-07, 2.6912e-07, 4.2258e-10, 1.2274e-08, 1.6205e-08, 6.8845e-03,\n",
       "         4.2366e-08, 1.0084e-03, 1.0051e-11, 6.0991e-08, 5.9479e-05, 3.0089e-07,\n",
       "         1.0457e-07, 1.0861e-06, 1.7942e-08],\n",
       "        [3.2874e-02, 8.7020e-01, 9.4098e-04, 5.4018e-06, 1.7196e-02, 1.4816e-04,\n",
       "         6.9787e-02, 2.3893e-03, 3.3928e-03, 8.3591e-09, 2.0681e-06, 1.8063e-04,\n",
       "         4.8037e-07, 1.3615e-05, 2.7229e-10, 1.5926e-07, 6.9677e-08, 2.7945e-03,\n",
       "         1.4226e-07, 1.4324e-07, 1.4628e-09, 2.9372e-07, 6.2441e-05, 2.6690e-09,\n",
       "         6.6205e-08, 3.0447e-07, 1.1589e-05],\n",
       "        [1.9885e-03, 1.6493e-03, 1.7620e-03, 2.6816e-08, 1.1006e-05, 3.8341e-08,\n",
       "         4.6922e-04, 2.8261e-04, 4.0897e-04, 7.4699e-09, 1.2972e-05, 2.7785e-07,\n",
       "         5.5099e-09, 5.7544e-09, 3.2746e-09, 2.3030e-09, 8.6758e-10, 3.3127e-03,\n",
       "         2.5955e-08, 9.9010e-01, 7.2810e-12, 2.6291e-09, 1.5071e-09, 4.3107e-08,\n",
       "         5.2522e-09, 1.9369e-09, 7.9347e-10],\n",
       "        [4.8448e-04, 6.7353e-01, 2.7911e-01, 2.1140e-06, 4.3538e-02, 3.2675e-05,\n",
       "         6.3815e-04, 1.7482e-03, 9.8905e-07, 1.3839e-06, 2.2845e-07, 3.7349e-04,\n",
       "         3.0348e-08, 7.6997e-06, 4.0004e-10, 2.3296e-08, 8.8982e-06, 1.2151e-05,\n",
       "         1.9501e-06, 2.6009e-08, 1.1720e-10, 9.4896e-08, 5.1282e-04, 1.6769e-09,\n",
       "         9.0199e-07, 4.2272e-09, 2.8689e-07],\n",
       "        [1.1338e-01, 9.3415e-02, 8.6294e-03, 1.9105e-06, 1.1567e-02, 8.5004e-05,\n",
       "         7.5517e-01, 8.7340e-03, 1.0087e-03, 1.1263e-07, 2.9845e-05, 2.1015e-05,\n",
       "         3.4339e-07, 2.6912e-07, 4.2258e-10, 1.2274e-08, 1.6205e-08, 6.8845e-03,\n",
       "         4.2366e-08, 1.0084e-03, 1.0051e-11, 6.0991e-08, 5.9479e-05, 3.0089e-07,\n",
       "         1.0457e-07, 1.0861e-06, 1.7942e-08],\n",
       "        [1.3054e-03, 5.5582e-04, 5.0064e-03, 1.1044e-08, 4.5891e-05, 1.4069e-07,\n",
       "         1.1994e-02, 2.2102e-04, 1.9789e-05, 2.0843e-08, 9.3902e-06, 2.6762e-07,\n",
       "         4.0711e-09, 7.0449e-10, 2.9725e-11, 2.2218e-10, 1.1264e-10, 6.4577e-04,\n",
       "         5.3366e-10, 9.8020e-01, 7.8460e-15, 8.2428e-10, 5.7689e-08, 2.4774e-07,\n",
       "         5.7338e-09, 1.0914e-08, 1.0209e-11],\n",
       "        [2.2034e-03, 5.5473e-01, 5.9385e-03, 3.1215e-05, 1.2547e-01, 1.1656e-03,\n",
       "         1.0201e-02, 1.9557e-05, 8.3458e-04, 5.1708e-05, 2.1156e-07, 5.9800e-02,\n",
       "         7.5205e-07, 4.4775e-04, 2.3546e-08, 2.8549e-05, 2.0061e-04, 4.2562e-02,\n",
       "         5.3093e-03, 2.4158e-06, 5.3896e-07, 6.7064e-05, 5.1013e-06, 4.1585e-09,\n",
       "         1.8020e-05, 8.3502e-10, 1.9091e-01],\n",
       "        [1.3941e-08, 9.9494e-01, 1.1920e-06, 5.7990e-07, 1.6983e-05, 1.3687e-07,\n",
       "         4.8181e-09, 7.8613e-04, 1.5159e-05, 5.9125e-09, 1.7173e-08, 3.3807e-04,\n",
       "         5.4998e-07, 6.2234e-04, 8.7009e-08, 1.7241e-07, 4.4671e-07, 9.9591e-08,\n",
       "         2.1941e-06, 2.8380e-16, 2.2960e-03, 1.0355e-06, 1.6253e-09, 6.2674e-12,\n",
       "         3.0625e-09, 4.7292e-12, 9.7617e-04],\n",
       "        [4.7024e-11, 2.7116e-08, 3.0069e-16, 8.7858e-08, 7.0930e-11, 3.3058e-08,\n",
       "         1.2733e-10, 6.1617e-11, 1.6346e-03, 5.8381e-12, 1.8846e-10, 3.2518e-11,\n",
       "         1.0150e-10, 6.2781e-06, 9.4240e-09, 9.8187e-08, 9.5510e-10, 2.8260e-07,\n",
       "         3.0541e-06, 1.1246e-22, 6.7648e-04, 1.7940e-09, 1.5829e-13, 4.2567e-16,\n",
       "         6.9204e-10, 1.1433e-11, 9.9768e-01],\n",
       "        [8.8373e-05, 9.4174e-01, 1.8059e-04, 4.2483e-07, 5.9293e-03, 2.0409e-05,\n",
       "         7.8870e-07, 8.4499e-05, 2.0288e-05, 7.3372e-07, 4.8060e-08, 3.6324e-04,\n",
       "         4.2718e-09, 8.3421e-05, 1.2515e-06, 8.8003e-07, 9.4072e-04, 2.0869e-05,\n",
       "         5.2536e-03, 8.1334e-10, 8.0122e-05, 2.8775e-07, 8.2786e-08, 4.6027e-11,\n",
       "         3.7697e-05, 1.7994e-11, 4.5155e-02],\n",
       "        [1.5515e-09, 2.0128e-07, 4.7761e-08, 2.2991e-06, 4.7608e-07, 4.3619e-06,\n",
       "         7.2693e-07, 2.8856e-10, 3.0755e-06, 2.7370e-06, 2.0033e-06, 2.9922e-06,\n",
       "         4.7727e-07, 6.6962e-06, 6.9475e-06, 7.0613e-05, 2.5976e-05, 5.4288e-04,\n",
       "         5.4218e-02, 1.3171e-08, 1.6523e-03, 2.2933e-04, 1.5669e-09, 2.0115e-08,\n",
       "         1.1946e-03, 3.4245e-09, 9.4203e-01],\n",
       "        [1.0164e-09, 9.5005e-09, 8.1608e-05, 2.3520e-06, 1.7479e-06, 4.2158e-07,\n",
       "         7.4095e-11, 5.1099e-11, 4.7063e-09, 9.6712e-05, 1.6797e-08, 1.2570e-02,\n",
       "         4.7750e-06, 1.0511e-07, 2.9599e-04, 8.9995e-05, 4.1011e-03, 3.6553e-07,\n",
       "         8.2246e-01, 2.1082e-07, 3.5305e-02, 8.4599e-04, 8.5721e-11, 8.2426e-07,\n",
       "         1.2172e-01, 2.0032e-12, 2.4209e-03],\n",
       "        [1.1602e-13, 6.5631e-08, 1.7846e-10, 1.3430e-10, 3.4929e-10, 2.5201e-07,\n",
       "         9.3898e-15, 7.0761e-08, 1.4892e-08, 2.9979e-09, 4.2554e-08, 3.7825e-09,\n",
       "         9.3952e-05, 6.3859e-04, 1.9593e-07, 1.2442e-09, 5.1274e-07, 1.8729e-11,\n",
       "         1.3174e-07, 3.0810e-19, 9.9918e-01, 2.6177e-06, 3.9691e-09, 2.4604e-11,\n",
       "         1.7272e-05, 6.5626e-09, 6.7570e-05],\n",
       "        [1.1338e-01, 9.3415e-02, 8.6294e-03, 1.9105e-06, 1.1567e-02, 8.5004e-05,\n",
       "         7.5517e-01, 8.7340e-03, 1.0087e-03, 1.1263e-07, 2.9845e-05, 2.1015e-05,\n",
       "         3.4339e-07, 2.6912e-07, 4.2258e-10, 1.2274e-08, 1.6205e-08, 6.8845e-03,\n",
       "         4.2366e-08, 1.0084e-03, 1.0051e-11, 6.0991e-08, 5.9479e-05, 3.0089e-07,\n",
       "         1.0457e-07, 1.0861e-06, 1.7942e-08],\n",
       "        [5.0165e-05, 1.7891e-02, 8.6801e-08, 1.5701e-07, 5.4918e-04, 8.0726e-06,\n",
       "         1.7536e-04, 1.1732e-07, 4.3947e-04, 2.1758e-08, 4.5376e-09, 2.0205e-04,\n",
       "         3.7133e-08, 1.5205e-04, 6.2619e-10, 3.0051e-07, 8.6917e-07, 2.2728e-03,\n",
       "         2.3174e-04, 2.5654e-10, 3.1845e-07, 7.5287e-07, 3.4257e-08, 8.8026e-12,\n",
       "         2.6738e-08, 1.2228e-10, 9.7803e-01],\n",
       "        [2.2061e-11, 1.1695e-06, 3.1109e-11, 1.2846e-06, 5.6189e-09, 7.3834e-08,\n",
       "         2.0989e-14, 1.6816e-09, 3.0159e-09, 5.0843e-10, 7.8911e-12, 2.9162e-03,\n",
       "         2.4944e-08, 2.0512e-06, 2.9843e-06, 1.2758e-06, 3.8790e-05, 2.0522e-09,\n",
       "         3.4807e-01, 1.1500e-19, 5.9818e-01, 9.9254e-08, 3.7476e-13, 3.6918e-13,\n",
       "         1.9944e-08, 3.7967e-13, 5.0786e-02],\n",
       "        [5.5844e-10, 9.2342e-08, 4.2809e-11, 1.8265e-08, 1.6080e-10, 1.5035e-08,\n",
       "         8.1969e-14, 7.4358e-07, 1.1484e-07, 1.9743e-09, 2.5621e-08, 2.4655e-09,\n",
       "         4.4019e-09, 4.9160e-08, 1.6222e-05, 1.4089e-09, 2.8749e-08, 2.0703e-09,\n",
       "         6.1004e-06, 3.7757e-18, 9.9960e-01, 9.4211e-08, 2.0910e-11, 1.4258e-13,\n",
       "         3.3543e-06, 3.0839e-10, 3.7229e-04],\n",
       "        [1.3941e-13, 1.3973e-08, 8.0799e-11, 1.6016e-05, 1.4414e-09, 1.8674e-05,\n",
       "         7.8567e-11, 4.3809e-12, 4.6990e-07, 2.2878e-07, 3.8747e-08, 5.7334e-08,\n",
       "         3.5642e-09, 1.3315e-05, 9.0018e-07, 3.6706e-06, 2.3129e-05, 4.7393e-07,\n",
       "         2.0351e-04, 2.3662e-17, 1.3931e-02, 1.2522e-05, 2.5000e-10, 1.0020e-13,\n",
       "         2.7066e-06, 8.7625e-10, 9.8577e-01],\n",
       "        [3.2544e-03, 1.4225e-01, 2.9449e-01, 2.5199e-06, 7.6946e-03, 1.2052e-07,\n",
       "         6.1683e-05, 5.1370e-01, 2.7461e-05, 1.1327e-05, 9.9052e-05, 1.2209e-02,\n",
       "         1.8577e-03, 2.2212e-05, 1.3995e-03, 3.4109e-06, 1.8788e-03, 1.2573e-05,\n",
       "         1.7236e-02, 2.0029e-05, 3.4753e-03, 1.5452e-05, 4.4470e-08, 1.4299e-04,\n",
       "         1.3001e-04, 1.5794e-10, 9.5465e-07],\n",
       "        [2.4937e-10, 3.5233e-06, 1.9577e-10, 1.1260e-05, 5.3703e-09, 6.2635e-04,\n",
       "         1.9127e-09, 5.5388e-07, 1.0419e-02, 9.1377e-08, 3.5598e-05, 6.2920e-09,\n",
       "         4.0237e-05, 5.8626e-03, 7.8697e-07, 5.3877e-09, 7.9221e-08, 2.0720e-06,\n",
       "         5.4335e-08, 1.4816e-19, 8.6861e-01, 1.6560e-05, 1.6894e-07, 3.5827e-12,\n",
       "         2.3494e-05, 4.0299e-05, 1.1431e-01]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T19:01:15.889212Z",
     "start_time": "2025-07-11T19:01:15.883234Z"
    }
   },
   "cell_type": "code",
   "source": "probs[torch.arange(32), Y]",
   "id": "478c5de482d1d67e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.5004e-05, 4.9227e-08, 3.3886e-13, 2.5331e-10, 1.0225e-02, 1.2274e-08,\n",
       "        2.5989e-09, 2.2685e-09, 2.3873e-09, 1.1633e-08, 2.0684e-07, 1.5779e-02,\n",
       "        9.3415e-02, 6.2441e-05, 1.6493e-03, 4.8448e-04, 1.1263e-07, 9.8020e-01,\n",
       "        5.5473e-01, 1.1920e-06, 3.3058e-08, 4.2718e-09, 4.7727e-07, 9.5005e-09,\n",
       "        1.1602e-13, 1.0084e-03, 3.0051e-07, 3.8790e-05, 1.1484e-07, 2.2878e-07,\n",
       "        1.4225e-01, 2.4937e-10])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T19:02:42.700356Z",
     "start_time": "2025-07-11T19:02:42.693735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = -probs[torch.arange(32), Y].log().mean()\n",
    "loss"
   ],
   "id": "9522075bb7c83bbc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.7562)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "466dbbf976dfc201"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
